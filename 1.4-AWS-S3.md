# 1.4 AWS S3

## 1.4.1 AWS S3 Security

- S3 is private by default. Any other permissions explicitly granted.
- S3 buckets use **resource** policies.
  - Like identity policies, but attached to a bucket
  - resource perspective permissions: who can access bucket, etc.
- Identity policies can only be attached to identities in own account;
  - Have no way using Identity policy to control access to another account
  - Attaching policy to resource allows controlling access to same and different
    accounts.
- Resource Policies allow/deny anonymous principals (anon access).

- S3 resource policies have express `"Principal"` inside of statement.

### When to use Identity vs Resource Policy
- Identity
  - Controlling many different resources
  - You have a preference for mananging permission in IAM
  - Using same account
- Resource/Bucket
  - Just controlling S3
  - Anonymous or Cross-Account
- ACLs: Never use unless absolutely need to

### Block Public Access

- Used as a big hammer for blocking public access. Bypasses any resource
  policies and locks down public access.

### Access Control Lists (ACLs)

- Legacy, AWS dont recommend; inflexible and simple permissions.

## 1.4.2 AWS S3 Static Hosting

- Static hosting requires an index and error document
- When static hosting is enabled on bucket, website endpoint is created
- Custom Domain name must match bucket name via R53

- Always consider offloading any large data to S3 bucket to avoid high compute
  costs. Cheaper to host from dedicated S3 than compute server. host from
  dedicated S3 than compute server.
- S3 is great for Out-of-band pages (maintenance page, server error etc)

## 1.4.3 Object Versioning

- Versioning allows multiple version of objects within a bucket.
- Versioning uses an id on each object and when object is overwritten (uses same
  key), the old version is retained with exisiting id, and new version is
  assigned new id. This newest version is the Latest Version or Current Version.
- If no id is specified, Latest Version is returned.
- **Cannot disable** object versioning on a bucket once enabled but can suspend
  versioning.

- Delete markers can be used to mark an object as 'deleted' but doesn't actually
  delete the object.
- Delete marker can also be removed to restore access to the previously deleted
  file and its version history.
- Version delete can be used to completely version of an object. If it is the
  latest version, it will be deleted and the previous version will become the
  Current Version.

### MFA Delete

- Is enabled in version configuration.
- When enabled, MFA is required to:
  - change bucket versioning state;
  - delete versions.
- Serial number (MFA) + Code passed with API Calls to make changes.

## 1.4.4 S3 Performance Optimization

- Single PUT uploads for large data is risky in S3.
  - Stream fails, upload fails.
  - Requires full restart.
  - Has max upload size of 5GB

- Multipart Upload solves issue with breaking data up.
  - Has a minimum data size of 100MB, recommended to use as soon as over
    threshold
  - 10,000 max parts, ranging from 5MB -> 5GB
  - Last part can be smaller than 5MB
  - Parts can fail and be restarted
  - Transfer rate = speeds of all parts

- S3 Transfer Acceleration, when enabled, transits data to its closest Edge
  Location which then propagates data to AWS via its global network which is
  often direct lines to destination.
  - Without S3 Transfer Acceleration, path of data to destination is out whim of
    ISP and global internet
  - S3 Transfer Accel has restrictions: bucket name cannot contain periods and
    needs to be DNS compatible in its naming.
  - Creates a specific endpoint that needs to be used.

## 1.4.5 Key Management Service (KMS)

- Allows creation, store and manage keys.
- Regional and public
- Handles Symmetric and Asymmetric Keys.
- Allows cryptographic operations (encrypt, decrypt, etc)
- **Keys never leave KMS** - Provides **FIPS 140-2 (L3)**
  - https://aws.amazon.com/blogs/security/aws-kms-now-fips-140-2-level-3-what-does-this-mean-for-you/

- KMS Keys are logical (ID, date, policy, etc) and backed by physical key
  material
  - KMS Keys can be generated or Imported
  - KMS Keys can be used for up to 4KB of data

- KMS Keys are isolated to region and never leave.

### Data Encryption Key (DEKs)

- Formal method to work around 4KB data.
- GenerateDataKey - works on >4KB
  - Returns Plaintext and Ciphertext version of key.
  - Encrypt data using plaintext key.
  - Discard plaintext after encrypting data.
  - Store encrypted key with data.
- Decrypting data requires sending encrypted DEK to KMS and using (now)
  plaintext key to decrypt data payload and then discard key.
- Service like S3 handles encrypting data automatically with KMS.

### Key Policies

- Keys in KMS are required specific resource policies to allow it; IAM policy
  alone cannot grant access.
  - This is intentional to disallow product administrators access to information
    that may be sensitive (such as user data, etc).

## 1.4.6 AWS S3 Server-Side Encryption (SSE)

- Buckets aren't encrypted, objects are.
- All data in stream from user to AWS is encrypted.

- Server-Side Encryption with Customer-Provided Keys (SSE-C)
  - User provides key on request and AWS encrypts and destroys key;
  - Data is stored now encrypted at rest;
  - User requests data again with same key, AWS decrypts and returns data.

- Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3) (Default)
  - Provide plaintext data, S3 generates key for each object and encrypts data;
  - AWS then uses envelope encryption by encrypting the key used (DEK) and
    discarding the plaintext key;
  - This encrypted key and blob are then stored on S3, with both S3 and DEK
    being opaque to users of the AWS service.

- Server-Side Encryption with KMS Keys Stored in AWS KMS (SSE-KMS) (Default)
  - Admin creates a KMS Key in AWS KMS;
  - User sends plaintext data to S3, and S3 generates a DEK;
  - S3 encrypts plaintext and discards the plaintext key and then ciphertext and
    DEK are stored on S3 storage.

  - This solution has one benefit of role separation: admin can administer but
    cannot read data.

- Dual-Layer Server-Side Encryption with AWS KMS Keys (DSSE-KMS)
  - Similar to SSE-KMS, but applies two independent layers of server-side encryption to objects at rest.
  - S3 generates two separate DEKs for each object, both protected by KMS key.
  - Designed to meet high-compliance (CNSSP15) that require redundant encryption
    layers.
  - Supports S3 Bucket Keys to reduce KMS request traffic and costs by creating
    local cache of the key within S3

### S3 Bucket Keys

- KMS has regional limitations for throttling, therefore when performing many
  encryption targets, we often need to generate a Bucket Key.
- Bucket Keys offload the work needed to generate DEKs by being a provisioned
  time limited sub-key from KMS.
- When offloaded to Bucket Key, CloudTrail KMS now show bucket, not object.

- S3 Bucket keys work with same and different region replication - object
  encryption is maintained.
- Replicating plaintext into a bucket using bucket keys will cause the object to
  be encrypted at the destination side (often with ETAG changes)

## 1.4.7 AWS S3 Storage Classes

- S3 Standard
  - At least 3 AZs in the AWS region.
    - 99.999999999% (11 9's) of durability - for 10M objects, 1 object loss per
      10k years.
    - Uses Content-MD5 Checksums and Cyclic Redundancy Checks (CRCs) to detect
      and fix any data corruption.
  - **Important**: When object stored durably, responds with HTTP/1.1 200 OK.
  - Most balanced cost:
    - GB/m fee for data stored.
    - $ per GB charged for transfer OUT (IN is free)
    - price per 1,000 requests.
    - No specific retrieval fee, no minimum duration, no minimum size
  - S3 standard has 'milliseconds' first byte latency and objects can be made
    publicly available.
  - S3 standard used for **Frequently Accessed** Data which is **important** and
    **Non Replaceable**.

- S3 Standard Infrequent Access (IA)
  - Same Availability (3AZ) and durability, replication as Standard.
  - Similar costs to Standard with caveat of:
    - Cost per GB data retrieval fee, overall cost increases with frequent data
      access.
    - Minimum duration charge of 30 days - objects can be stored for less but
      minimum billing always applies.
    - Minimum capacity charge of 128KB per object.
  - Perfect for long-lived data, which is important but access is infrequent.
    Not good for lots of files or temp data which is constantly replaced.

- S3 One Zone Infrequent Access (One Zone-IA)
  - No resilience via multi-AZ, only one AZ.
  - 11 nines of durability within the AZ.
  - per GB data retrieval fee (same as IA)
  - Minimum duration charge of 30 days)
  - minimum capacity charge of 128KB per object.
  - Great for long-lived data which is **NON-CRITICAL** and **REPLACEABLE** and
    access is **infrequent**.

- S3 Glacier - Instant
  - Has same durability, replication etc as other S3.
  - Similar to S3 Standard-IA (cheaper storage, more expensive retrieval, longer
    minimum)
  - Minimum charge for 128KB per object.
  - Minimum storage duration of **90 days**
  - Used for long-lived data, accessed once per quarter with millisecond access.

- S3 Glacier - Flexible
  - Same durability and replication
  - Objects are cold and not immediately available and requires retrieval
    process.
  - Data is retrieved to S3 Standard-IA temporarily
    - Expedited (1-5 minutes)
    - Standard (3-5 hours)
    - Bulk (5-12 hours)
    - Faster = More Expensive
    - First byte latency = minutes or hours
  - Great for Archival data where frequent or realtime access isn't needed (e.g.
    Yearly) minutes-hours retrieval.

- S3 Glacier - Deep Archive
  - Same durability and replication
  - Objects have 180 day min duration and 40KB min size.
  - Requires retrieval job for access. Restored to Standard-IA.
  - Retrieval times:
    - Standard (12 hours)
    - Bulk (up to 48 hours)
    - First byte latency = hours or days.
  - Great for archival data that rarely if ever needs to be access e.g. legal or
    regulation data storage.

- S3 Intelligent-Tiering
  - Intelligent tiering that moves data between different access tiers depending
    on access to object.
  - Optional archive is available and can be implemented with customer
    application.
  - Great for long lived data with changing or unknown patterns.
